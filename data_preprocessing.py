import pandas as pd
from google.colab import drive

# ============================================================
# 0. åŸºç¤è¨­å®š
# ============================================================
pd.set_option("display.max_columns", None)
drive.mount('/drive', force_remount=True)


# ============================================================
# 1. é€šç”¨å·¥å…·ï¼šè¼‰å…¥ CSVã€æ¨™æº–åŒ–æ¬„ä½
# ============================================================

def load_csv(file_path, encoding="utf-8"):
    """è®€å– CSV + æ¨™æº–åŒ–æ¬„ä½åç¨± + å›å‚³ DataFrame"""
    print(f"\nğŸ“‚ Loading file: {file_path}")

    try:
        df = pd.read_csv(file_path, encoding=encoding, on_bad_lines="skip", low_memory=False)
    except UnicodeDecodeError:
        print("âš ï¸ UTF-8 è§£ç¢¼å¤±æ•—ï¼Œæ”¹ç”¨ latin1")
        df = pd.read_csv(file_path, encoding="latin1", on_bad_lines="skip", low_memory=False)

    # æ¨™æº–åŒ–æ¬„ä½
    df.columns = [col.lower().strip() for col in df.columns]

    rename_dict = {"public_date": "date", "datadate": "date"}
    df.rename(columns={c: rename_dict[c] for c in df.columns if c in rename_dict}, inplace=True)

    # gvkey / permno è‡ªå‹•æ¨™æº–åŒ–
    for col in df.columns:
        if "gvkey" in col:
            df.rename(columns={col: "gvkey"}, inplace=True)
        if "permno" in col:
            df.rename(columns={col: "permno"}, inplace=True)

    # æ—¥æœŸæ ¼å¼
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")

    print(f"âœ” rows: {len(df)}, columns: {len(df.columns)}")
    return df


# ============================================================
# 2. åˆ†çµ„æ’åº
# ============================================================

def sort_by_group(df, date_col="date"):
    """ä¾ç…§ gvkey æˆ– permno åˆ†çµ„ä¸¦æ’åº"""
    key = "gvkey" if "gvkey" in df.columns else "permno"
    return df.sort_values([key, date_col])


# ============================================================
# 3. ç§»é™¤é‡è¤‡è³‡æ–™ï¼ˆCRSPï¼‰
# ============================================================

def remove_duplicate_permno_date(df, output_path):
    """åˆªé™¤ permno+date é‡è¤‡è³‡æ–™ï¼Œè¼¸å‡ºè¢«åˆªé™¤è³‡æ–™"""
    print("\nğŸ§¹ Removing duplicate (permno, date) rows...")

    before = len(df)
    dup = df[df.duplicated(subset=["permno", "date"], keep=False)]
    dup.to_csv(output_path, index=False)

    df_clean = df.drop_duplicates(subset=["permno", "date"], keep="first")

    print(f"âœ” Before: {before}, After: {len(df_clean)}, Removed: {len(dup)}")
    return df_clean


# ============================================================
# 4. æ‰¾å‡ºé€£çºŒæœˆä»½è³‡æ–™
# ============================================================

def extract_continuous_monthly(df, id_col, delete_file, missing_file):
    """æ‹†åˆ†é€£çºŒ vs ä¸é€£çºŒæœˆä»½è³‡æ–™ï¼Œä¸¦è¼¸å‡ºä¸é€£çºŒéƒ¨åˆ† + ç¼ºå¤±æœˆä»½"""
    print(f"\nğŸ“… Checking monthly continuity for {id_col}...")

    df["date"] = pd.to_datetime(df["date"])
    continuous, removed, missing_records = [], [], []

    for id_value, group in df.groupby(id_col):
        group = group.sort_values("date")
        months = pd.date_range(group["date"].min(), group["date"].max(), freq="MS")
        missing = months.difference(group["date"].dt.to_period("M").dt.to_timestamp())

        if len(missing) == 0:
            continuous.append(group)
        else:
            removed.append(group)
            for m in missing:
                missing_records.append([id_value, m])

    removed_df = pd.concat(removed) if removed else pd.DataFrame()
    continuous_df = pd.concat(continuous) if continuous else pd.DataFrame()

    removed_df.to_csv(delete_file, index=False)
    pd.DataFrame(missing_records, columns=[id_col, "missing_date"]).to_csv(missing_file, index=False)

    print(f"âœ” Continuous groups: {len(continuous_df)}, Removed groups: {len(removed_df)}")
    return continuous_df


# ============================================================
# 5. åˆä½µ CRSP Ã— IBES
# ============================================================

def merge_crsp_ibes(crsp, ibes):
    """ä»¥ permno + æœˆä»½åˆä½µ"""
    crsp["date"] = crsp["date"].dt.to_period("M")
    ibes["date"] = ibes["date"].dt.to_period("M")

    merged = pd.merge(crsp, ibes, on=["permno", "date"], how="inner")
    merged["date"] = merged["date"].dt.to_timestamp()

    print(f"\nğŸ”— Merge done â†’ rows={len(merged)}, permno={merged['permno'].nunique()}")
    return merged


# ============================================================
# 6. Cut-offï¼ˆåˆªé™¤ 1970 å¹´ä»¥å‰è³‡æ–™ï¼‰
# ============================================================

def remove_data_before_year(data, date_column, cutoff_year):
    """åˆªé™¤æŸå¹´ä»½ä»¥å‰çš„è³‡æ–™"""
    data[date_column] = pd.to_datetime(data[date_column], errors="coerce")
    data["year"] = data[date_column].dt.year

    before = len(data)
    data = data[data["year"] > cutoff_year].drop(columns=["year"])
    after = len(data)

    print(f"\nâ›” Cut-off applied: removed {before - after} rows â‰¤ {cutoff_year}")
    return data


# ============================================================
# 7. ç¼ºå¤±å€¼æª¢æŸ¥èˆ‡åˆªé™¤ä¸è‰¯è‚¡ç¥¨
# ============================================================

def preprocess_data(df, columns_to_check):
    print(f"\nğŸ“Œ Preprocess â†’ åŸå§‹ç­†æ•¸: {df.shape[0]}")

    deleted = []
    drop_list = []

    for (permno, ncusip), group in df.groupby(["permno", "ncusip"]):

        for col in columns_to_check:
            if col not in df.columns:
                continue

            # é€£çºŒ â‰¥ 8 å€‹ NA â†’ åˆªé™¤è©²è‚¡ç¥¨
            consec_na = (
                group[col].isna()
                .astype(int)
                .groupby(group[col].notna().astype(int).cumsum())
                .sum()
                .max()
            )

            if consec_na >= 8:
                drop_list.append((permno, ncusip))
                deleted.append(group)
                break

    mask = df.set_index(["permno", "ncusip"]).index.isin(drop_list)
    df_clean = df[~mask]

    print(f"âœ” Removed {len(drop_list)} bad permno/ncusip groups")

    pd.concat(deleted).to_csv("/drive/MyDrive/è«–æ–‡/data/deleted_groups.csv", index=False)

    return df_clean


# ============================================================
# 8. å¡«è£œç¼ºå¤±å€¼ï¼ˆå‰å¾Œå¡«è£œï¼‰
# ============================================================

def fill_missing_values(df, cols):
    print("\nğŸ§© Filling missing values...")

    for col in cols:
        if col in df.columns:
            df[col] = df.groupby(["permno", "ncusip"])[col].apply(
                lambda x: x.ffill().bfill()
            )

    print("âœ” Missing values filled.")
    return df


# ============================================================
# 9. ä¸»æµç¨‹åŸ·è¡Œ
# ============================================================

IBES_raw = "/drive/MyDrive/è«–æ–‡/data/financial_ratio_all_IBES.csv"
CRSP_raw = "/drive/MyDrive/è«–æ–‡/data/CRSP_Stock_price_Monthly_final.csv"

dup_CRSP = "/drive/MyDrive/è«–æ–‡/data/price_duplicate.csv"
noncon_IBES = "/drive/MyDrive/è«–æ–‡/data/non_continuous_data1.csv"
noncon_IBES_dates = "/drive/MyDrive/è«–æ–‡/data/non_continuous_date1.csv"
noncon_CRSP = "/drive/MyDrive/è«–æ–‡/data/non_continuous_data2.csv"
noncon_CRSP_dates = "/drive/MyDrive/è«–æ–‡/data/non_continuous_date2.csv"

merged_final_path = "/drive/MyDrive/è«–æ–‡/data/merged_data_final.csv"

# Step 1: Load
crsp = load_csv(CRSP_raw)
ibes = load_csv(IBES_raw)

# Step 2: Sort
crsp = sort_by_group(crsp)
ibes = sort_by_group(ibes)

# Step 3: Remove duplicate rows (CRSP only)
crsp = remove_duplicate_permno_date(crsp, dup_CRSP)

# Step 4: Keep only continuous monthly data
ibes_clean = extract_continuous_monthly(ibes, "gvkey", noncon_IBES, noncon_IBES_dates)
crsp_clean = extract_continuous_monthly(crsp, "permno", noncon_CRSP, noncon_CRSP_dates)

# Step 5: Merge CRSP Ã— IBES
merged = merge_crsp_ibes(crsp_clean, ibes_clean)

# â­ Step 6: Remove data â‰¤ 1970
merged = remove_data_before_year(merged, "date", 1970)

# Step 7: Preprocess â€” remove bad stocks
cols_to_check = [
    "bm","evm","pe_exi","pe_inc","ptb","gprof","gpm","npm",
    "opmad","roa","roe","cfm","cash_debt","short_debt",
    "curr_debt","de_ratio","debt_at","quick_ratio",
    "curr_ratio","rect_turn","at_turn","rd_sale","prc"
]
merged = preprocess_data(merged, cols_to_check)

# Step 8: Fill missing values
merged = fill_missing_values(merged, cols_to_check)

# Step 9: Save result
merged.to_csv(merged_final_path, index=False)
print("\nğŸ‰ å®Œæˆï¼Final dataset saved:", merged_final_path)

