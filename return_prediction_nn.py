import os
import random
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from dateutil.relativedelta import relativedelta
import time
import psutil
from google.colab import drive

drive.mount('/drive', force_remount=True)

# è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿çµæœå¯é‡ç¾
def set_random_seed(seed):
    os.environ['PYTHONHASHSEED'] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)

# å®šç¾©è¨“ç·´ + é æ¸¬å‡½å¼ï¼ˆä½¿ç”¨ rolling windowï¼‰
def train_and_predict(data, start_date, end_date, prediction_date, growth_period, seed=10):
    set_random_seed(seed)

    # æ“·å–è¨“ç·´è¦–çª—è³‡æ–™
    window_data = data.loc[start_date:end_date]
    if window_data.empty:
        print(f"ğŸ“­ ç„¡å¯ç”¨è³‡æ–™å€é–“ï¼š{start_date} ~ {end_date}")
        return None, None, None, None, None

    # å– permno èˆ‡ ncusip åšå”¯ä¸€æ¨™è­˜
    stock_ids = window_data[['permno', 'ncusip']].copy()

    # åˆ†é›¢ç‰¹å¾µèˆ‡ç›®æ¨™è®Šæ•¸
    X = window_data[['bm', 'pe_exi', 'pe_inc', 'ptb', 'gprof', 'gpm',
                     'npm', 'opmad', 'roa', 'roe', 'cfm', 'cash_debt',
                     'short_debt', 'curr_debt', 'de_ratio', 'debt_at',
                     'quick_ratio', 'curr_ratio', 'rect_turn', 'at_turn', 'rd_sale']]

    y = window_data[f'PRC GROWTH {growth_period}m']

    # åˆ†å‰²è¨“ç·´é›† / é©—è­‰é›†
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.1, random_state=seed
    )

    # ç‰¹å¾µæ¨™æº–åŒ–
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_val = sc.transform(X_val)

    # å»ºç«‹ç¥ç¶“ç¶²è·¯æ¨¡å‹
    model = tf.keras.models.Sequential([
        tf.keras.layers.Dense(10, activation='relu', input_shape=(X_train.shape[1],)),
        tf.keras.layers.Dense(1)
    ])

    # ç·¨è­¯æ¨¡å‹
    model.compile(optimizer='adam', loss='mse')

    # è¨“ç·´æ¨¡å‹
    start_time = time.time()
    model.fit(X_train, y_train, validation_data=(X_val, y_val),
              epochs=50, batch_size=512, verbose=2)
    end_time = time.time()

    training_time = end_time - start_time

    # æº–å‚™é æ¸¬è³‡æ–™
    prediction_data = data[data.index == prediction_date]
    if prediction_data.empty:
        print(f"ğŸ“­ ç„¡é æ¸¬æ—¥æœŸè³‡æ–™ï¼š{prediction_date}")
        return None, None, None, None

    X_pred = prediction_data[['bm', 'pe_exi', 'pe_inc', 'ptb', 'gprof', 'gpm',
                              'npm', 'opmad', 'roa', 'roe', 'cfm', 'cash_debt',
                              'short_debt', 'curr_debt', 'de_ratio', 'debt_at',
                              'quick_ratio', 'curr_ratio', 'rect_turn', 'at_turn', 'rd_sale']]

    X_pred = sc.transform(X_pred)

    # é€²è¡Œé æ¸¬
    y_pred = model.predict(X_pred).flatten()

    return y_pred, prediction_data[f'PRC GROWTH {growth_period}m'], \
           prediction_data[['permno', 'ncusip']], X_pred, training_time


# ä¾åºè™•ç†ä¸åŒè¦–çª—èˆ‡ä¸åŒé æ¸¬å¹´æœŸ
def process_all_windows_and_years(base_path):
    growth_periods = [6, 9]  # é æ¸¬ 6 å€‹æœˆèˆ‡ 9 å€‹æœˆå ±é…¬
    prediction_years = [2, 3, 4, 5]  # é æ¸¬ horizonï¼š2ã€3ã€4ã€5 å¹´

    for growth_period in growth_periods:
        dataset_path = f'/drive/MyDrive/è«–æ–‡/data/final_result_{growth_period}m.csv'

        if os.path.exists(dataset_path):
            dataset = pd.read_csv(dataset_path)
            dataset['date'] = pd.to_datetime(dataset['date'])
            dataset = dataset.sort_values('date')
            dataset.set_index('date', inplace=True)

            # ç§»é™¤ä¸éœ€è¦çš„æ¬„ä½
            dataset = dataset.drop(columns=['evm'])

            for years in prediction_years:

                # æ‰¾å‡ºæœ€æ—©æ—¥æœŸ
                earliest_date = dataset.index.min()
                print(f"ğŸ“… è³‡æ–™æœ€æ—©æ—¥æœŸï¼š{earliest_date}")

                # è¨­å®šç¬¬ä¸€å€‹é æ¸¬æ—¥æœŸ
                prediction_date = earliest_date + relativedelta(years=years)

                all_results = []
                total_training_time = 0
                start_memory = psutil.virtual_memory().used

                # æ¯æœˆæ»¾å‹•é æ¸¬
                while prediction_date <= dataset.index.max():

                    start_date = prediction_date - relativedelta(years=years) + relativedelta(days=1)
                    end_date = prediction_date - relativedelta(days=1)

                    y_pred, y_true, stock_ids, X_pred, training_time = \
                        train_and_predict(dataset, start_date, end_date, prediction_date, growth_period)

                    total_training_time += training_time

                    if y_pred is not None and y_true is not None:
                        results_df = pd.DataFrame({
                            'permno': stock_ids['permno'].values,
                            'ncusip': stock_ids['ncusip'].values,
                            'Date': [prediction_date] * len(y_pred),
                            'True Values': y_true.values,
                            'Predicted Values': y_pred,
                            'Window Start': [start_date] * len(y_pred),
                            'Window End': [end_date] * len(y_pred)
                        })

                        all_results.append(results_df)
                        print(f"ğŸ“Œ å·²å®Œæˆæ—¥æœŸ {prediction_date} çš„é æ¸¬")

                    prediction_date += relativedelta(months=1)

                # è¨ˆç®—è¨˜æ†¶é«”ä½¿ç”¨é‡
                end_memory = psutil.virtual_memory().used

                # åˆä½µæ‰€æœ‰é æ¸¬çµæœ
                final_results_df = pd.concat(all_results)

                # è¨ˆç®—æ•´é«” RMSE
                overall_rmse = np.sqrt(mean_squared_error(
                    final_results_df['True Values'], final_results_df['Predicted Values']
                ))
                print(f"ğŸ“‰ æ•´é«” RMSEï¼š{overall_rmse}")

                # è¨ˆç®—æ•´é«” MAE
                overall_mae = mean_absolute_error(
                    final_results_df['True Values'], final_results_df['Predicted Values']
                )
                print(f"ğŸ“‰ æ•´é«” MAEï¼š{overall_mae}")

                print(f"â±ï¸ ç¸½è¨“ç·´æ™‚é–“ï¼š{total_training_time} ç§’")
                print(f"ğŸ§  è¨˜æ†¶é«”ä½¿ç”¨é‡ï¼š{end_memory - start_memory} bytes")

                # è¼¸å‡ºçµæœ
                final_results_filename = f'/drive/MyDrive/è«–æ–‡/data/NN1_{growth_period}M_{years}y_max_predictions_vs_true_val_adjust.csv'
                final_results_df.to_csv(final_results_filename, index=False)
                print(f"ğŸ“ çµæœå·²å„²å­˜ï¼š{final_results_filename}")


# åŸ·è¡Œæ‰€æœ‰è¦–çª—èˆ‡é æ¸¬å¹´ä»½
process_all_windows_and_years('/drive/MyDrive/è«–æ–‡/data/')
